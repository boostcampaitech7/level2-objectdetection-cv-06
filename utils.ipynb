{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋을 train_sep.json과 val.json으로 나누었습니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋 로드\n",
    "with open('../../dataset/train.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "df = pd.DataFrame(data['images'])\n",
    "\n",
    "# 데이터의 20%를 랜덤으로 선택\n",
    "val_indices = np.random.choice(df.index, size=int(len(df) * 0.1), replace=False)\n",
    "val_df = df.loc[val_indices]\n",
    "train_df = df.drop(val_indices)\n",
    "\n",
    "# annotations 필터링\n",
    "train_annotations = []\n",
    "val_annotations = []\n",
    "\n",
    "for annotation in data['annotations']:\n",
    "    if annotation['image_id'] in val_df['id'].values:\n",
    "        val_annotations.append(annotation)\n",
    "    else:\n",
    "        train_annotations.append(annotation)\n",
    "\n",
    "# train_sep.json 및 val.json 파일로 저장\n",
    "train_data = {\n",
    "    'images': train_df.to_dict(orient='records'),\n",
    "    'annotations': train_annotations,\n",
    "    'categories': data['categories']  # categories는 그대로 유지\n",
    "}\n",
    "val_data = {\n",
    "    'images': val_df.to_dict(orient='records'),\n",
    "    'annotations': val_annotations,\n",
    "    'categories': data['categories']  # categories는 그대로 유지\n",
    "}\n",
    "\n",
    "with open('../../dataset/train_sep.json', 'w') as f:\n",
    "    json.dump(train_data, f, indent=4)\n",
    "\n",
    "with open('../../dataset/val_sep.json', 'w') as f:\n",
    "    json.dump(val_data, f, indent=4)\n",
    "\n",
    "print(\"데이터셋을 train_sep.json과 val.json으로 나누었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터셋 로드\n",
    "with open('../../dataset/train.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "df = pd.DataFrame(data['images'])\n",
    "\n",
    "# 이미지 id를 기준으로 annotation에서 레이블을 추출\n",
    "image_labels = {image['id']: [] for image in data['images']}\n",
    "\n",
    "# 각 이미지에 해당하는 레이블 추가\n",
    "for annotation in data['annotations']:\n",
    "    image_id = annotation['image_id']\n",
    "    category_id = annotation['category_id']\n",
    "    image_labels[image_id].append(category_id)\n",
    "\n",
    "# 각 이미지의 멀티라벨 리스트를 데이터프레임에 추가\n",
    "df['labels'] = df['id'].map(image_labels)\n",
    "\n",
    "# MultiLabelBinarizer를 사용하여 멀티라벨을 이진 매트릭스로 변환\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df['labels'])\n",
    "\n",
    "# MultilabelStratifiedKFold 사용\n",
    "mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Split을 저장할 리스트 초기화\n",
    "splits = []\n",
    "\n",
    "# 각 fold에 대한 분할 수행\n",
    "for train_idx, val_idx in mskf.split(df, y):\n",
    "    train_df = df.iloc[train_idx]\n",
    "    val_df = df.iloc[val_idx]\n",
    "\n",
    "    # 각 split에 대해 annotations 필터링\n",
    "    train_annotations = []\n",
    "    val_annotations = []\n",
    "\n",
    "    for annotation in data['annotations']:\n",
    "        if annotation['image_id'] in val_df['id'].values:\n",
    "            val_annotations.append(annotation)\n",
    "        else:\n",
    "            train_annotations.append(annotation)\n",
    "\n",
    "    # train 및 validation 데이터를 저장\n",
    "    train_data = {\n",
    "        'images': train_df.to_dict(orient='records'),\n",
    "        'annotations': train_annotations,\n",
    "        'categories': data['categories']\n",
    "    }\n",
    "    val_data = {\n",
    "        'images': val_df.to_dict(orient='records'),\n",
    "        'annotations': val_annotations,\n",
    "        'categories': data['categories']\n",
    "    }\n",
    "    \n",
    "    # 각 fold에 대해 저장\n",
    "    split_num = len(splits) + 1\n",
    "    with open(f'../../dataset/train_split_{split_num}.json', 'w') as f:\n",
    "        json.dump(train_data, f, indent=4)\n",
    "    \n",
    "    with open(f'../../dataset/val_split_{split_num}.json', 'w') as f:\n",
    "        json.dump(val_data, f, indent=4)\n",
    "\n",
    "    # 저장된 split 추가\n",
    "    splits.append((train_idx, val_idx))\n",
    "\n",
    "print(f'{len(splits)}개의 fold로 데이터가 분할되었습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "# COCO JSON 파일 경로\n",
    "coco_file = 'path/to/output.bbox.json'# 결과를 저장할 CSV 파일 경로\n",
    "output_csv_file = 'path/to/pascal_voc_submission.csv'\n",
    "\n",
    "# COCO 데이터셋 로드\n",
    "coco = COCO(coco_file)\n",
    "img_ids = coco.getImgIds()\n",
    "class_num = 10  # 클래스 수\n",
    "\n",
    "# 제출 양식 후처리\n",
    "prediction_strings = []\n",
    "file_names = []\n",
    "\n",
    "# COCO 형식의 예측 결과 로드\n",
    "with open(coco_file) as f:\n",
    "    coco_results = json.load(f)\n",
    "\n",
    "# COCO 결과에서 output 추출\n",
    "output = coco_results['annotations']  # 'annotations' 키에서 바운딩 박스 정보 추출\n",
    "\n",
    "# 예측 결과를 CSV 형식으로 변환\n",
    "for i, img_id in enumerate(img_ids):\n",
    "    prediction_string = ''\n",
    "    image_info = coco.loadImgs(img_id)[0]  # 이미지 정보를 가져옴\n",
    "\n",
    "    # 클래스별 예측된 bbox가 있는지 확인 후 처리\n",
    "    for j in range(class_num):\n",
    "        # COCO에서 클래스별 예측 결과 필터링\n",
    "        filtered_results = [o for o in output if o['category_id'] == j and o['image_id'] == img_id]\n",
    "        \n",
    "        if len(filtered_results) > 0:\n",
    "            for o in filtered_results:\n",
    "                # bbox는 [x, y, width, height] 형식이므로 [x, y, x+w, y+h]로 변환\n",
    "                bbox = o['bbox']\n",
    "                prediction_string += f'{j} {o[\"score\"]:.6f} {bbox[0]:.2f} {bbox[1]:.2f} {bbox[0] + bbox[2]:.2f} {bbox[1] + bbox[3]:.2f} '\n",
    "    # 예측된 결과가 없으면 '0 0 0 0 0 0' 형식으로 채움\n",
    "    if prediction_string == '':\n",
    "        prediction_string = '0 0 0 0 0 0'\n",
    "    \n",
    "    prediction_strings.append(prediction_string.strip())  # 공백 제거\n",
    "    file_names.append(image_info['file_name'])  # 파일 이름 추가\n",
    "\n",
    "# 제출 데이터 프레임 생성\n",
    "submission = pd.DataFrame()\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission['image_id'] = file_names\n",
    "\n",
    "# 제출 파일 저장\n",
    "submission.to_csv(output_csv_file, index=None)\n",
    "\n",
    "# 결과 확인\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# 결과물 파일 경로\n",
    "results_file = './results.pkl'  # 결과물 파일 경로\n",
    "output_csv_file = './pascal_voc_submission.csv'  # 결과를 저장할 CSV 파일 경로\n",
    "\n",
    "# 결과물 파일 로드\n",
    "with open(results_file, 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "# 결과물에서 필요한 정보 추출\n",
    "prediction_strings = []\n",
    "file_names = []\n",
    "\n",
    "# 결과물에서 예측 결과를 CSV 형식으로 변환\n",
    "for result in results:\n",
    "    prediction_string = ''\n",
    "    image_info = result['image_info']  # 이미지 정보를 가져옴\n",
    "\n",
    "    # 클래스별 예측된 bbox가 있는지 확인 후 처리\n",
    "    for class_id, bboxes in result['bboxes'].items():\n",
    "        for bbox in bboxes:\n",
    "            # bbox는 [x, y, width, height] 형식이므로 [x, y, x+w, y+h]로 변환\n",
    "            prediction_string += f'{class_id} {bbox[\"score\"]:.6f} {bbox[\"bbox\"][0]:.2f} {bbox[\"bbox\"][1]:.2f} {bbox[\"bbox\"][0] + bbox[\"bbox\"][2]:.2f} {bbox[\"bbox\"][1] + bbox[\"bbox\"][3]:.2f} '\n",
    "    # 예측된 결과가 없으면 '0 0 0 0 0 0' 형식으로 채움\n",
    "    if prediction_string == '':\n",
    "        prediction_string = '0 0 0 0 0 0'\n",
    "    \n",
    "    prediction_strings.append(prediction_string.strip())  # 공백 제거\n",
    "    file_names.append(image_info['file_name'])  # 파일 이름 추가\n",
    "\n",
    "# 제출 데이터 프레임 생성\n",
    "submission = pd.DataFrame()\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission['image_id'] = file_names\n",
    "\n",
    "# 제출 파일 저장\n",
    "submission.to_csv(output_csv_file, index=None)\n",
    "\n",
    "# 결과 확인\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
